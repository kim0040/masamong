# -*- coding: utf-8 -*-
"""
Specific Case Verification (Hyunmin's Unit)

Tests if 'Olympic' (ì˜¬ë¦¼í”½) or 'Unit' (ë¶€ëŒ€) retrieval works in the new Kakao V2.1 data.
"""

import sys
import os
import json
import numpy as np
import torch
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# Load Config
DATA_PATH = "data/kakao_store/room1"
VECTORS_PATH = os.path.join(DATA_PATH, "vectors.npy")
METADATA_PATH = os.path.join(DATA_PATH, "metadata.json")
MODEL_NAME = "dragonkue/multilingual-e5-small-ko-v2"

def main():
    print(f"ðŸ”Ž [ì •ë°€ ê²€ì¦] ë°ì´í„° ë¡œë“œ ì¤‘... ({DATA_PATH})")
    
    if not os.path.exists(VECTORS_PATH):
        print("âŒ ë°ì´í„° ì—†ìŒ.")
        return

    vectors = np.load(VECTORS_PATH)
    with open(METADATA_PATH, 'r', encoding='utf-8') as f:
        metadata = json.load(f)

    print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(metadata)}ê°œ")

    device = "mps" if torch.backends.mps.is_available() else "cpu"
    model = SentenceTransformer(MODEL_NAME, device=device)

    # Queries related to the user's complaint
    queries = [
        "í˜„ë¯¼ì´ ë¶€ëŒ€",
        "ê¹€í˜„ë¯¼ ë¶€ëŒ€",
        "ì˜¬ë¦¼í”½ ë¶€ëŒ€",
        "í˜„ë¯¼ì´ êµ°ëŒ€ ì–´ë””"
    ]

    for q in queries:
        print(f"\nðŸ§ª Query: '{q}'")
        q_vec = model.encode([f"query: {q}"], normalize_embeddings=True)
        sims = cosine_similarity(q_vec, vectors)[0]
        top_k = np.argsort(sims)[::-1][:3]
        
        found = False
        for rank, idx in enumerate(top_k, 1):
            item = metadata[idx]
            match_in_text = "ì˜¬ë¦¼í”½" in item['text'] or "ë¶€ëŒ€" in item['text']
            
            print(f"  Rank {rank} (Score: {sims[idx]:.4f}) {'[MATCH]' if match_in_text else ''}")
            
            # Print snippet
            snippet = item['text'].replace('\n', ' ')[:150]
            print(f"    {snippet}...")
            
            if match_in_text: 
                found = True

    # Check the rank of actual "Olympic" chunks for the query "í˜„ë¯¼ì´ ë¶€ëŒ€"
    print("\nðŸ”Ž [ìˆœìœ„ ë¶„ì„] 'í˜„ë¯¼ì´ ë¶€ëŒ€' ê²€ìƒ‰ ì‹œ 'ì˜¬ë¦¼í”½' í¬í•¨ ì²­í¬ì˜ ìˆœìœ„ëŠ”?")
    
    # 1. Identify Target Chunk IDs
    target_indices = []
    for idx, item in enumerate(metadata):
        if "ì˜¬ë¦¼í”½" in item['text'] and "ë¶€ëŒ€" in item['text']:
            target_indices.append(idx)
            
    print(f"  ðŸŽ¯ 'ì˜¬ë¦¼í”½+ë¶€ëŒ€' í¬í•¨ ì²­í¬ ê°œìˆ˜: {len(target_indices)}ê°œ")
    
    # 2. Check Rank
    q = "í˜„ë¯¼ì´ ë¶€ëŒ€"
    q_vec = model.encode([f"query: {q}"], normalize_embeddings=True)
    sims = cosine_similarity(q_vec, vectors)[0]
    
    # Sort all indices by score descending
    sorted_indices = np.argsort(sims)[::-1]
    
    for rank, idx in enumerate(sorted_indices, 1):
        if idx in target_indices:
            score = sims[idx]
            text = metadata[idx]['text'].replace('\n', ' ')[:100]
            print(f"  ðŸ… Rank {rank} (Score: {score:.4f}): {text}...")
            if rank > 20:
                break # Show only top relevant matches or first few deep ones

if __name__ == "__main__":
    main()
