# -*- coding: utf-8 -*-
"""
RAG V2.1 Verification Script (Precision Test)

This script loads the new embeddings and performs a cosine similarity search
to verify that we can retrieve specific chunks ("Dialog Details") instead of just summaries.
"""

import sys
import os
import json
import numpy as np
import torch
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# Load Config
DATA_PATH = "data/kakao_store/room1"
VECTORS_PATH = os.path.join(DATA_PATH, "vectors.npy")
METADATA_PATH = os.path.join(DATA_PATH, "metadata.json")
MODEL_NAME = "dragonkue/multilingual-e5-small-ko-v2"

def main():
    print(f"ğŸ” [RAG V2.1 ê²€ì¦] ë°ì´í„° ë¡œë“œ ì¤‘... ({DATA_PATH})")
    
    # 1. Load Data
    if not os.path.exists(VECTORS_PATH) or not os.path.exists(METADATA_PATH):
        print(f"âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ({VECTORS_PATH})")
        return

    vectors = np.load(VECTORS_PATH)
    with open(METADATA_PATH, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
        
    print(f"âœ… ë²¡í„° ë¡œë“œ ì™„ë£Œ: {vectors.shape}")
    print(f"âœ… ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(metadata)}ê°œ")

    # 2. Load Model
    print(f"â³ ëª¨ë¸ ë¡œë“œ ì¤‘... ({MODEL_NAME})")
    device = "mps" if torch.backends.mps.is_available() else "cpu"
    model = SentenceTransformer(MODEL_NAME, device=device)
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # 3. Test Queries
    # Case: "ë³‘ì›ì˜¥ìƒ" -> This specific keyword was in the original text (chunk) but might be missed by generic summary
    # Check if we retrieve the chunk containing "ë³‘ì›ì˜¥ìƒ"
    queries = [
        "ë³‘ì›ì˜¥ìƒ", 
        "ìš´ì „ë©´í—ˆ"
    ]

    for q in queries:
        print(f"\nğŸ§ª [ê²€ìƒ‰ í…ŒìŠ¤íŠ¸] ê²€ìƒ‰ì–´: '{q}'")
        
        # Embed Query (E5 expects 'query: ' prefix)
        q_vec = model.encode([f"query: {q}"], normalize_embeddings=True)
        
        # Similarity Search
        sims = cosine_similarity(q_vec, vectors)[0]
        
        # Get Top 3
        top_k_indices = np.argsort(sims)[::-1][:3]
        
        found_target = False
        for rank, idx in enumerate(top_k_indices, 1):
            item = metadata[idx]
            score = sims[idx]
            
            # Extract content showing it's a chunk
            content = item.get('text', '')
            summary_part = item.get('summary', '')
            original_part = item.get('original_text', '') # V2 metadata might have this? No, V2.1 metadata has 'text' formatted.
            
            # In V2.1, 'text' field is "[Summary] ... [Detail] ..."
            # Let's peek at the structure
            
            print(f"  ğŸ¥ˆ Rank {rank} (Score: {score:.4f})")
            if q in content:
                print(f"     âœ… ì •ë‹µ í‚¤ì›Œë“œ '{q}' í¬í•¨ë¨!")
                found_target = True
            else:
                print(f"     âŒ ì •ë‹µ í‚¤ì›Œë“œ ë¯¸í¬í•¨")
                
            # Show a snippet
            snippet = content.replace('\n', ' ')[:100]
            print(f"     ğŸ“„ ë‚´ìš©: {snippet}...")
            
        if found_target:
            print(f"  ğŸ‰ '{q}' ê²€ìƒ‰ ì„±ê³µ! (ìƒì„¸ ëŒ€í™” ë‚´ìš©ì—ì„œ ì°¾ì•„ëƒ„)")
        else:
            print(f"  âš ï¸ '{q}' ê²€ìƒ‰ ì‹¤íŒ¨.")

if __name__ == "__main__":
    main()
