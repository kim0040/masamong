# -*- coding: utf-8 -*-
import discord
from discord.ext import commands
import google.generativeai as genai
from datetime import datetime, timedelta, time
import asyncio
import pytz
from collections import deque
from typing import Dict, Any, Tuple

import config
from logger_config import logger

KST = pytz.timezone('Asia/Seoul')

class AIHandler(commands.Cog):
    """Gemini AI ìƒí˜¸ì‘ìš© (ìë°œì  ì‘ë‹µ, ì˜ë„ ë¶„ì„, ì‚¬ìš©ìë³„ ëŒ€í™” ê¸°ë¡)"""

    def __init__(self, bot: commands.Bot):
        self.bot = bot
        self.ai_user_cooldowns: Dict[int, datetime] = {}
        self.gemini_configured = False
        self.api_call_lock = asyncio.Lock()
        self.minute_request_timestamps = deque()
        self.conversation_histories: Dict[int, deque] = {}
        self.last_proactive_response_times: Dict[int, datetime] = {}

        if config.GEMINI_API_KEY:
            try:
                genai.configure(api_key=config.GEMINI_API_KEY)
                self.model = genai.GenerativeModel(config.AI_MODEL_NAME)
                self.intent_model = genai.GenerativeModel(config.AI_INTENT_MODEL_NAME)
                logger.info("Gemini API ë° ëª¨ë¸ ì„¤ì • ì™„ë£Œ.")
                self.gemini_configured = True
            except Exception as e:
                logger.critical(f"Gemini API ì„¤ì • ì‹¤íŒ¨: {e}. AI ê¸°ëŠ¥ ë¹„í™œì„±í™”ë¨.", exc_info=True)

    @property
    def is_ready(self) -> bool:
        """AI í•¸ë“¤ëŸ¬ê°€ ëª¨ë“  ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ì¤€ë¹„ê°€ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        return self.gemini_configured

    async def _check_global_rate_limit(self) -> Tuple[bool, str | None]:
        async with self.api_call_lock:
            now = datetime.now()
            one_minute_ago = now - timedelta(minutes=1)
            while self.minute_request_timestamps and self.minute_request_timestamps[0] < one_minute_ago:
                self.minute_request_timestamps.popleft()

            if len(self.minute_request_timestamps) >= config.API_RPM_LIMIT:
                logger.warning(f"ë¶„ë‹¹ Gemini API í˜¸ì¶œ ì œí•œ ë„ë‹¬ ({len(self.minute_request_timestamps)}/{config.API_RPM_LIMIT}).")
                return True, config.MSG_AI_RATE_LIMITED

        # ì¼ì¼ í˜¸ì¶œ ì œí•œ (DB í™•ì¸)
        if await utils.is_api_limit_reached('gemini_daily_calls', config.API_RPD_LIMIT):
            return True, config.MSG_AI_DAILY_LIMITED

        return False, None

    def _record_api_call(self):
        """API í˜¸ì¶œì„ ê¸°ë¡í•©ë‹ˆë‹¤ (ë¶„ë‹¹ ì œí•œìš©)."""
        now = datetime.now()
        self.minute_request_timestamps.append(now)
        # ì¼ì¼ ì¹´ìš´í„°ëŠ” DBì—ì„œ ì§ì ‘ ì¦ê°€ì‹œí‚¤ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë¶„ë‹¹ ì¹´ìš´íŠ¸ë§Œ ë¡œê¹…
        logger.debug(f"Gemini API í˜¸ì¶œ ê¸°ë¡ë¨. (ì§€ë‚œ 1ë¶„ê°„: {len(self.minute_request_timestamps)}íšŒ)")


    def _is_on_cooldown(self, user_id: int) -> Tuple[bool, float]:
        now = datetime.now()
        if user_id in self.ai_user_cooldowns:
            time_since_last = now - self.ai_user_cooldowns[user_id]
            if time_since_last.total_seconds() < config.AI_COOLDOWN_SECONDS:
                return True, config.AI_COOLDOWN_SECONDS - time_since_last.total_seconds()
        return False, 0.0

    def _update_cooldown(self, user_id: int):
        self.ai_user_cooldowns[user_id] = datetime.now()
        cutoff_time = datetime.now() - timedelta(seconds=config.AI_COOLDOWN_SECONDS * 10)
        self.ai_user_cooldowns = {uid: t for uid, t in self.ai_user_cooldowns.items() if t >= cutoff_time}

    def is_proactive_on_cooldown(self, channel_id: int) -> bool:
        cooldown_seconds = config.AI_PROACTIVE_RESPONSE_CONFIG.get("cooldown_seconds", 90)
        last_time = self.last_proactive_response_times.get(channel_id)
        if last_time and (datetime.now() - last_time).total_seconds() < cooldown_seconds:
            logger.debug(f"ì±„ë„({channel_id}) ìë°œì  ì‘ë‹µ ì¿¨ë‹¤ìš´ ì¤‘.")
            return True
        return False

    def update_proactive_cooldown(self, channel_id: int):
        self.last_proactive_response_times[channel_id] = datetime.now()
        logger.info(f"ì±„ë„({channel_id}) ìë°œì  ì‘ë‹µ ì¿¨ë‹¤ìš´ ì‹œì‘.")

    def add_message_to_history(self, message: discord.Message):
        """ëŒ€í™” ê¸°ë¡ì— ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
        if not config.AI_MEMORY_ENABLED: return
        
        channel_id = message.channel.id
        channel_config = config.CHANNEL_AI_CONFIG.get(channel_id)
        
        # AI ì„¤ì •ì´ ìˆëŠ” ì±„ë„ì˜ ë©”ì‹œì§€ë§Œ ê¸°ë¡
        if channel_config and channel_config.get("allowed", False):
            if channel_id not in self.conversation_histories:
                self.conversation_histories[channel_id] = deque(maxlen=config.AI_MEMORY_MAX_MESSAGES)

            # [ê°œì„ ] ë´‡ì˜ ë©”ì‹œì§€ì™€ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ êµ¬ë¶„í•˜ì—¬ ì €ì¥
            if message.author == self.bot.user:
                role = "model"
                # ë´‡ì˜ ë©”ì‹œì§€ëŠ” 'User(ID|ì´ë¦„):' ì ‘ë‘ì‚¬ ì—†ì´ ìˆœìˆ˜ ë‚´ìš©ë§Œ ì €ì¥
                formatted_content = message.content
            else:
                role = "user"
                # ì‚¬ìš©ìì˜ ë©”ì‹œì§€ëŠ” ëˆ„ê°€ ë§í–ˆëŠ”ì§€ ì‹ë³„ìë¥¼ ë¶™ì—¬ì„œ ì €ì¥
                user_identifier = f"User({message.author.id}|{message.author.display_name})"
                formatted_content = f"{user_identifier}: {message.content}"
            
            self.conversation_histories[channel_id].append({"role": role, "parts": [{"text": formatted_content}]})
            logger.debug(f"ì±„ë„({channel_id}) ë©”ëª¨ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€: {formatted_content[:50]}...")

    async def should_proactively_respond(self, message: discord.Message) -> bool:
        if not self.is_ready: return False
        history = self.conversation_histories.get(message.channel.id)
        if not history or len(history) < 2: return False
        
        # [ê°œì„ ] ëŒ€í™” ê¸°ë¡ í¬ë§·ì— ë§ì¶° í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
        formatted_history = "\n".join([item['parts'][0]['text'] for item in history])
        
        try:
            is_limited, _ = await self._check_global_rate_limit()
            if is_limited: return False
            
            prompt = (f"{config.AI_PROACTIVE_RESPONSE_CONFIG['gatekeeper_persona']}\n\n"
                      f"--- ìµœê·¼ ëŒ€í™” ë‚´ìš© ---\n{formatted_history}\n\n"
                      "ì´ ìƒí™©ì—ì„œ ì±—ë´‡ì´ ë¼ì–´ë“¤ì–´ë„ ë ê¹Œ? (Yes/No)")
            
            logger.debug(f"ìë°œì  ì‘ë‹µ ì—¬ë¶€ íŒë‹¨ ìš”ì²­ (ì±„ë„: {message.channel.id})...")
            async with self.api_call_lock:
                self._record_api_call()
                response = await self.intent_model.generate_content_async(prompt)
            decision = response.text.strip().lower()
            logger.info(f"ìë°œì  ì‘ë‹µ íŒë‹¨ ê²°ê³¼: '{decision}'")
            return 'yes' in decision
        except Exception as e:
            logger.error(f"ìë°œì  ì‘ë‹µ ì—¬ë¶€ íŒë‹¨ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return False

    async def analyze_intent(self, message: discord.Message) -> str:
        if not config.AI_INTENT_ANALYSIS_ENABLED or not self.is_ready: return "Chat"
        
        user_query = message.content.replace(f'<@!{self.bot.user.id}>', '').replace(f'<@{self.bot.user.id}>', '').strip()
        if not user_query: return "Chat"
        
        try:
            is_limited, _ = await self._check_global_rate_limit()
            if is_limited: return "Chat"
            
            prompt = f"{config.AI_INTENT_PERSONA}\n\nì‚¬ìš©ì ë©”ì‹œì§€: \"{user_query}\""
            logger.debug(f"ì˜ë„ ë¶„ì„ ìš”ì²­: {user_query[:50]}...")
            
            async with self.api_call_lock:
                self._record_api_call()
                response = await self.intent_model.generate_content_async(prompt)
            
            intent = response.text.strip()
            logger.info(f"ì˜ë„ ë¶„ì„ ê²°ê³¼: '{intent}' (ì›ë³¸: '{user_query[:50]}...')")
            
            valid_intents = ['Time', 'Weather', 'Command', 'Chat', 'Mixed']
            return intent if intent in valid_intents else 'Chat'
        except Exception as e:
            logger.error(f"AI ì˜ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return "Chat"

    async def generate_creative_text(self, channel: discord.TextChannel, author: discord.User, prompt_key: str, context: Dict[str, Any] | None = None) -> str | None:
        if not self.is_ready:
            logger.warning(f"ì°½ì˜ì  í…ìŠ¤íŠ¸ ìƒì„± ë¶ˆê°€({prompt_key}): AI í•¸ë“¤ëŸ¬ ë¯¸ì¤€ë¹„.")
            return config.MSG_AI_ERROR

        prompt_template = config.AI_CREATIVE_PROMPTS.get(prompt_key)
        if not prompt_template:
            logger.error(f"ì°½ì˜ì  í…ìŠ¤íŠ¸ ìƒì„± ë¶ˆê°€: configì—ì„œ í”„ë¡¬í”„íŠ¸ í‚¤ '{prompt_key}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ.")
            return config.MSG_CMD_ERROR

        task_prompt = prompt_template.format(**(context or {}))
        channel_config = config.CHANNEL_AI_CONFIG.get(channel.id, {})

        return await self._generate_gemini_response(
            channel_id=channel.id,
            user_query=task_prompt,
            author=author,
            persona_config=channel_config,
            is_task=True
        )

    async def _generate_gemini_response(
        self,
        channel_id: int,
        user_query: str,
        author: discord.User,
        persona_config: dict,
        weather_info_str: str | None = None,
        is_task: bool = False
    ) -> str | None:
        if not self.is_ready: return config.MSG_AI_ERROR

        if not is_task:
            on_cooldown, remaining_time = self._is_on_cooldown(author.id)
            if on_cooldown:
                return config.MSG_AI_COOLDOWN.format(remaining=remaining_time)
            self._update_cooldown(author.id)

        is_limited, limit_message = await self._check_global_rate_limit()
        if is_limited: return limit_message

        user_persona_override = config.USER_SPECIFIC_PERSONAS.get(author.id)
        persona_cfg = user_persona_override or persona_config

        system_instructions = [
            persona_cfg.get("persona", ""),
            persona_cfg.get("rules", "")
        ]
        if weather_info_str:
            system_instructions.append(f"ì°¸ê³ í•  ë‚ ì”¨ ì •ë³´: {weather_info_str}")

        history = list(self.conversation_histories.get(channel_id, []))

        try:
            model = genai.GenerativeModel(
                config.AI_MODEL_NAME,
                safety_settings=config.GEMINI_SAFETY_SETTINGS,
                system_instruction="\n".join(filter(None, system_instructions))
            )
            
            # [ê°œì„ ] ì‘ì—… ìš”ì²­ ì‹œì—ëŠ” ì´ì „ ëŒ€í™”ë¥¼ ë¬´ì‹œí•˜ê³ , ì¼ë°˜ ëŒ€í™” ì‹œì—ë§Œ ëŒ€í™” ê¸°ë¡ì„ ì‚¬ìš©
            chat_session = model.start_chat(history=history if not is_task else [])

            # [ê°œì„ ] ì‘ì—… ìš”ì²­ ì‹œì—ëŠ” ì‚¬ìš©ì ì‹ë³„ì ì—†ì´ ìˆœìˆ˜ ì‘ì—… ë‚´ìš©ë§Œ ì „ë‹¬
            final_query = user_query if is_task else f"User({author.id}|{author.display_name}): {user_query}"
            
            logger.debug(f"AI ì²˜ë¦¬ ì‹œì‘ | {final_query[:80]}...")

            async with self.api_call_lock:
                self._record_api_call()
                response = await chat_session.send_message_async(final_query, stream=False)
                await utils.increment_api_counter('gemini_daily_calls')

            ai_response_text = response.text.strip()
            logger.info(f"AI ì‘ë‹µ ìƒì„± ì„±ê³µ (ê¸¸ì´: {len(ai_response_text)}): {ai_response_text[:50]}...")
            return ai_response_text

        except (genai.types.BlockedPromptException, genai.types.StopCandidateException) as security_exception:
            logger.warning(f"AI ìš”ì²­/ì‘ë‹µ ì°¨ë‹¨ë¨ | ì˜¤ë¥˜: {security_exception}")
            # [ê°œì„ ] ì‚¬ìš©ìì—ê²Œ ì–´ë–¤ ì¢…ë¥˜ì˜ ì˜¤ë¥˜ì¸ì§€ ëª…í™•íˆ ì „ë‹¬
            if 'prompt' in str(security_exception).lower():
                return config.MSG_AI_BLOCKED_PROMPT
            else:
                return config.MSG_AI_BLOCKED_RESPONSE
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}", exc_info=True)
            return config.MSG_AI_ERROR

    async def process_ai_message(self, message: discord.Message, weather_info: str | None = None):
        if not self.is_ready: return

        channel_config = config.CHANNEL_AI_CONFIG.get(message.channel.id)
        # [ìˆ˜ì •] 'allowed' í‚¤ë¥¼ ì •í™•íˆ í™•ì¸í•˜ë„ë¡ ë¡œì§ ë³€ê²½
        if not channel_config or not channel_config.get("allowed", False):
            # AIê°€ í—ˆìš©ë˜ì§€ ì•Šì€ ì±„ë„ì´ë¼ë„, ë‚ ì”¨ ì •ë³´ê°€ ìˆë‹¤ë©´ ë‚ ì”¨ë§Œì´ë¼ë„ ì•Œë ¤ì£¼ë„ë¡ ì²˜ë¦¬
            if weather_info:
                await message.reply(f"ğŸ“ {weather_info}", mention_author=False)
            return

        user_query = message.content.replace(f'<@!{self.bot.user.id}>', '').replace(f'<@{self.bot.user.id}>', '').strip()
        if not user_query and not weather_info:
            await message.reply(config.MSG_AI_NO_CONTENT.format(bot_name=self.bot.user.name), mention_author=False)
            return

        async with message.channel.typing():
            ai_response_text = await self._generate_gemini_response(
                channel_id=message.channel.id,
                user_query=user_query,
                author=message.author,
                persona_config=channel_config,
                weather_info_str=weather_info
            )

            if ai_response_text:
                # [ìˆ˜ì •] AI ì‘ë‹µì´ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ë©”ì‹œì§€ ì „ì†¡ ë° ê¸°ë¡
                bot_response_message = await message.reply(ai_response_text[:2000], mention_author=False)
                self.add_message_to_history(bot_response_message)

    async def generate_system_alert_message(self, channel_id: int, alert_context_info: str, alert_type: str = "ì¼ë°˜ ì•Œë¦¼") -> str | None:
        if not self.is_ready:
            logger.warning(f"ì‹œìŠ¤í…œ ì•Œë¦¼({alert_type}) ìƒì„± ë¶ˆê°€: AI í•¸ë“¤ëŸ¬ ë¯¸ì¤€ë¹„.")
            return None

        channel_config = config.CHANNEL_AI_CONFIG.get(channel_id, {})
        logger.info(f"ì‹œìŠ¤í…œ {alert_type} ìƒì„± ìš”ì²­: ì±„ë„={channel_id}, ë‚´ìš©='{alert_context_info[:100]}...'")

        user_query_for_alert = f"ë‹¤ìŒ ìƒí™©ì„ ë„ˆì˜ í˜ë¥´ì†Œë‚˜ì— ë§ê²Œ ì±„ë„ì— ì•Œë ¤ì¤˜: '{alert_context_info}'"
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ë´‡ ìì‹ ì´ ë³´ë‚´ëŠ” ê²ƒì´ë¯€ë¡œ, ë´‡ ì •ë³´ë¥¼ authorë¡œ ì‚¬ìš©
        system_author = self.bot.user

        generated_text = await self._generate_gemini_response(
            channel_id=channel_id,
            user_query=user_query_for_alert,
            author=system_author,
            persona_config=channel_config,
            is_task=True
        )
        return generated_text

async def setup(bot: commands.Bot):
    await bot.add_cog(AIHandler(bot))
