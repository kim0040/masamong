# -*- coding: utf-8 -*-
import discord
from discord.ext import commands
import google.generativeai as genai
from datetime import datetime, timedelta, time
import asyncio
import pytz
from collections import deque
from typing import Dict, Any, Tuple

import config
from logger_config import logger

KST = pytz.timezone('Asia/Seoul')

class AIHandler(commands.Cog):
    """Gemini AI ìƒí˜¸ì‘ìš© (ìë°œì  ì‘ë‹µ, ì˜ë„ ë¶„ì„, ì‚¬ìš©ìë³„ ëŒ€í™” ê¸°ë¡)"""

    def __init__(self, bot: commands.Bot):
        self.bot = bot
        self.ai_user_cooldowns: Dict[int, datetime] = {}
        self.gemini_configured = False
        self.api_call_lock = asyncio.Lock()
        self.minute_request_timestamps = deque()
        self.daily_request_count = 0
        self.daily_limit_reset_time = self._get_next_kst_midnight()
        self.conversation_histories: Dict[int, deque] = {}
        self.last_proactive_response_times: Dict[int, datetime] = {}

        if config.GEMINI_API_KEY:
            try:
                # (API ì„¤ì • ë¶€ë¶„ì€ ë³€ê²½ ì—†ìŒ)
                genai.configure(api_key=config.GEMINI_API_KEY)
                self.model = genai.GenerativeModel(config.AI_MODEL_NAME)
                self.intent_model = genai.GenerativeModel(config.AI_INTENT_MODEL_NAME)
                logger.info("Gemini API ë° ëª¨ë¸ ì„¤ì • ì™„ë£Œ.")
                self.gemini_configured = True
            except Exception as e:
                logger.critical(f"Gemini API ì„¤ì • ì‹¤íŒ¨: {e}. AI ê¸°ëŠ¥ ë¹„í™œì„±í™”ë¨.", exc_info=True)

    # (ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜ _get_next_kst_midnight, _check_global_rate_limit ë“±ì€ ë³€ê²½ ì—†ìŒ)
    @property
    def is_ready(self) -> bool:
        """AI í•¸ë“¤ëŸ¬ê°€ ëª¨ë“  ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ì¤€ë¹„ê°€ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        return self.gemini_configured

    def _get_next_kst_midnight(self) -> datetime:
        now_kst = datetime.now(KST)
        tomorrow = now_kst.date() + timedelta(days=1)
        return KST.localize(datetime.combine(tomorrow, time(0, 0)))

    async def _check_global_rate_limit(self) -> Tuple[bool, str | None]:
        async with self.api_call_lock:
            now = datetime.now()
            one_minute_ago = now - timedelta(minutes=1)
            while self.minute_request_timestamps and self.minute_request_timestamps[0] < one_minute_ago:
                self.minute_request_timestamps.popleft()

            if len(self.minute_request_timestamps) >= config.API_RPM_LIMIT:
                logger.warning(f"ë¶„ë‹¹ Gemini API í˜¸ì¶œ ì œí•œ ë„ë‹¬ ({len(self.minute_request_timestamps)}/{config.API_RPM_LIMIT}).")
                return True, config.MSG_AI_RATE_LIMITED

            now_kst = now.astimezone(KST)
            if now_kst >= self.daily_limit_reset_time:
                logger.info(f"KST ìì • ë„ë‹¬. Gemini API ì¼ì¼ ì¹´ìš´íŠ¸ ì´ˆê¸°í™” (ì´ì „: {self.daily_request_count}).")
                self.daily_request_count = 0
                self.daily_limit_reset_time = self._get_next_kst_midnight()

            if self.daily_request_count >= config.API_RPD_LIMIT:
                logger.warning(f"ì¼ì¼ Gemini API í˜¸ì¶œ ì œí•œ ë„ë‹¬ ({self.daily_request_count}/{config.API_RPD_LIMIT}).")
                return True, config.MSG_AI_DAILY_LIMITED
            return False, None

    def _record_api_call(self):
        now = datetime.now()
        self.minute_request_timestamps.append(now)
        self.daily_request_count += 1
        logger.debug(f"Gemini API í˜¸ì¶œ ê¸°ë¡ë¨. ë¶„ë‹¹: {len(self.minute_request_timestamps)}, ì¼ì¼: {self.daily_request_count}")

    def _is_on_cooldown(self, user_id: int) -> Tuple[bool, float]:
        now = datetime.now()
        if user_id in self.ai_user_cooldowns:
            time_since_last = now - self.ai_user_cooldowns[user_id]
            if time_since_last.total_seconds() < config.AI_COOLDOWN_SECONDS:
                return True, config.AI_COOLDOWN_SECONDS - time_since_last.total_seconds()
        return False, 0.0

    def _update_cooldown(self, user_id: int):
        self.ai_user_cooldowns[user_id] = datetime.now()
        cutoff_time = datetime.now() - timedelta(seconds=config.AI_COOLDOWN_SECONDS * 10)
        self.ai_user_cooldowns = {uid: t for uid, t in self.ai_user_cooldowns.items() if t >= cutoff_time}

    def is_proactive_on_cooldown(self, channel_id: int) -> bool:
        cooldown_seconds = config.AI_PROACTIVE_RESPONSE_CONFIG.get("cooldown_seconds", 90)
        last_time = self.last_proactive_response_times.get(channel_id)
        if last_time and (datetime.now() - last_time).total_seconds() < cooldown_seconds:
            logger.debug(f"ì±„ë„({channel_id}) ìë°œì  ì‘ë‹µ ì¿¨ë‹¤ìš´ ì¤‘.")
            return True
        return False

    def update_proactive_cooldown(self, channel_id: int):
        self.last_proactive_response_times[channel_id] = datetime.now()
        logger.info(f"ì±„ë„({channel_id}) ìë°œì  ì‘ë‹µ ì¿¨ë‹¤ìš´ ì‹œì‘.")
        
    def add_message_to_history(self, message: discord.Message):
        if not config.AI_MEMORY_ENABLED: return
        channel_id = message.channel.id
        channel_config = config.CHANNEL_AI_CONFIG.get(channel_id)
        if channel_config and channel_config.get("allowed", True):
            if channel_id not in self.conversation_histories:
                self.conversation_histories[channel_id] = deque(maxlen=config.AI_MEMORY_MAX_MESSAGES)
            role = "model" if message.author == self.bot.user else "user"
            user_identifier = f"User({message.author.id}|{message.author.display_name})"
            formatted_content = f"{user_identifier}: {message.content}"
            self.conversation_histories[channel_id].append({"role": role, "parts": [{"text": formatted_content}]})
            logger.debug(f"ì±„ë„({channel_id}) ë©”ëª¨ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€: {formatted_content[:50]}...")

    async def should_proactively_respond(self, message: discord.Message) -> bool:
        if not self.is_ready: return False
        history = self.conversation_histories.get(message.channel.id)
        if not history or len(history) < 2: return False
        formatted_history = "\n".join([item['parts'][0]['text'] for item in history])
        try:
            is_limited, _ = await self._check_global_rate_limit()
            if is_limited: return False
            prompt = (f"{config.AI_PROACTIVE_RESPONSE_CONFIG['gatekeeper_persona']}\n\n"
                      f"--- ìµœê·¼ ëŒ€í™” ë‚´ìš© ---\n{formatted_history}\n\n"
                      "ì´ ìƒí™©ì—ì„œ ì±—ë´‡ì´ ë¼ì–´ë“¤ì–´ë„ ë ê¹Œ? (Yes/No)")
            logger.debug(f"ìë°œì  ì‘ë‹µ ì—¬ë¶€ íŒë‹¨ ìš”ì²­ (ì±„ë„: {message.channel.id})...")
            async with self.api_call_lock:
                self._record_api_call()
                response = await self.intent_model.generate_content_async(prompt)
            decision = response.text.strip().lower()
            logger.info(f"ìë°œì  ì‘ë‹µ íŒë‹¨ ê²°ê³¼: '{decision}'")
            return 'yes' in decision
        except Exception as e:
            logger.error(f"ìë°œì  ì‘ë‹µ ì—¬ë¶€ íŒë‹¨ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return False

    async def analyze_intent(self, message: discord.Message) -> str:
        if not config.AI_INTENT_ANALYSIS_ENABLED or not self.is_ready: return "Chat"
        user_query = message.content.replace(f'<@!{self.bot.user.id}>', '').replace(f'<@{self.bot.user.id}>', '').strip()
        if not user_query: return "Chat"
        try:
            is_limited, _ = await self._check_global_rate_limit()
            if is_limited: return "Chat"
            prompt = f"{config.AI_INTENT_PERSONA}\n\nì‚¬ìš©ì ë©”ì‹œì§€: \"{user_query}\""
            logger.debug(f"ì˜ë„ ë¶„ì„ ìš”ì²­: {user_query[:50]}...")
            async with self.api_call_lock:
                self._record_api_call()
                response = await self.intent_model.generate_content_async(prompt)
            intent = response.text.strip()
            logger.info(f"ì˜ë„ ë¶„ì„ ê²°ê³¼: '{intent}' (ì›ë³¸: '{user_query[:50]}...')")
            valid_intents = ['Weather', 'Command', 'Chat', 'Mixed']
            return intent if intent in valid_intents else 'Chat'
        except Exception as e:
            logger.error(f"AI ì˜ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return "Chat"

    # [ë¡œì§ ê°œì„ ] generate_creative_text í•¨ìˆ˜ë¥¼ _generate_gemini_responseë¥¼ ì¬ì‚¬ìš©í•˜ë„ë¡ í†µí•©.
    # ì´ì œ ëª¨ë“  AI ì‘ë‹µ ìƒì„±ì´ ë‹¨ì¼í™”ëœ í˜ë¥´ì†Œë‚˜ ë¡œì§ì„ ë”°ë¦„.
    async def generate_creative_text(self, channel: discord.TextChannel, author: discord.User, prompt_key: str, context: Dict[str, Any] | None = None) -> str | None:
        """
        config.pyì— ì •ì˜ëœ ì‘ì—… ì§€ì‹œë¥¼ ì‚¬ìš©í•˜ì—¬ ì°½ì˜ì ì¸ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        í•­ìƒ ì±„ë„ì˜ ê¸°ë³¸ í˜ë¥´ì†Œë‚˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µí•©ë‹ˆë‹¤.
        """
        if not self.is_ready:
            logger.warning(f"ì°½ì˜ì  í…ìŠ¤íŠ¸ ìƒì„± ë¶ˆê°€({prompt_key}): AI í•¸ë“¤ëŸ¬ ë¯¸ì¤€ë¹„.")
            return config.MSG_AI_ERROR

        prompt_template = config.AI_CREATIVE_PROMPTS.get(prompt_key)
        if not prompt_template:
            logger.error(f"ì°½ì˜ì  í…ìŠ¤íŠ¸ ìƒì„± ë¶ˆê°€: configì—ì„œ í”„ë¡¬í”„íŠ¸ í‚¤ '{prompt_key}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ.")
            return config.MSG_CMD_ERROR

        # ì‘ì—… ì§€ì‹œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        task_prompt = prompt_template.format(**(context or {}))
        
        # ì±„ë„ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        channel_config = config.CHANNEL_AI_CONFIG.get(channel.id, {})

        # í•µì‹¬ ì‘ë‹µ ìƒì„± ë¡œì§ ì¬ì‚¬ìš©
        return await self._generate_gemini_response(
            channel_id=channel.id,
            user_query=task_prompt, # ì¼ë°˜ ì±„íŒ… ëŒ€ì‹  'ì‘ì—… ì§€ì‹œ'ë¥¼ ì¿¼ë¦¬ë¡œ ì „ë‹¬
            author=author,
            persona_config=channel_config,
            is_task=True # ì´ í˜¸ì¶œì´ ì¼ë°˜ ì±„íŒ…ì´ ì•„ë‹Œ ì‘ì—…ì„ì„ ëª…ì‹œ
        )

    async def _generate_gemini_response(
        self,
        channel_id: int,
        user_query: str,
        author: discord.User,
        persona_config: dict,
        weather_info_str: str | None = None,
        is_task: bool = False # ì‘ì—… ìš”ì²­ê³¼ ì¼ë°˜ ì±„íŒ…ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•œ í”Œë˜ê·¸
    ) -> str | None:
        """Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í†µí•©ëœ í•µì‹¬ ë¡œì§."""
        if not self.is_ready: return config.MSG_AI_ERROR

        # ì‘ì—… ìš”ì²­(is_task=True)ì´ ì•„ë‹ ë•Œë§Œ ì‚¬ìš©ì ì¿¨ë‹¤ìš´ ì²´í¬
        if not is_task:
            on_cooldown, remaining_time = self._is_on_cooldown(author.id)
            if on_cooldown:
                return config.MSG_AI_COOLDOWN.format(remaining=remaining_time)
            self._update_cooldown(author.id)

        is_limited, limit_message = await self._check_global_rate_limit()
        if is_limited: return limit_message

        user_persona_override = config.USER_SPECIFIC_PERSONAS.get(author.id)
        persona_cfg = user_persona_override or persona_config
        
        system_instructions = [
            persona_cfg.get("persona", ""),
            persona_cfg.get("rules", "")
        ]
        if weather_info_str:
            system_instructions.append(f"ì°¸ê³ í•  ë‚ ì”¨ ì •ë³´: {weather_info_str}")

        history = list(self.conversation_histories.get(channel_id, []))
        
        try:
            # [ë¡œì§ ê°œì„ ] ëª¨ë¸ê³¼ ì„¸ì…˜ ìƒì„±ì„ try ë¸”ë¡ ì•ˆìœ¼ë¡œ ì´ë™í•˜ì—¬ ì•ˆì •ì„± í™•ë³´
            model = genai.GenerativeModel(
                config.AI_MODEL_NAME,
                safety_settings=config.GEMINI_SAFETY_SETTINGS,
                system_instruction="\n".join(filter(None, system_instructions))
            )
            chat_session = model.start_chat(history=history if not is_task else []) # ì‘ì—… ìš”ì²­ ì‹œì—ëŠ” ì´ì „ ëŒ€í™” ë¬´ì‹œ

            user_identifier = f"User({author.id}|{author.display_name})"
            # ì‘ì—… ìš”ì²­ì¼ ê²½ìš°, ì‚¬ìš©ì ì‹ë³„ìë¥¼ ë¶™ì´ì§€ ì•Šê³  ìˆœìˆ˜ ì‘ì—… ë‚´ìš©ë§Œ ì „ë‹¬
            final_query = user_query if is_task else f"{user_identifier}: {user_query}"
            
            logger.debug(f"AI ì²˜ë¦¬ ì‹œì‘ | {final_query[:80]}...")
            
            async with self.api_call_lock:
                self._record_api_call()
                response = await chat_session.send_message_async(final_query)

            ai_response_text = response.text.strip()
            logger.info(f"AI ì‘ë‹µ ìƒì„± ì„±ê³µ (ê¸¸ì´: {len(ai_response_text)}): {ai_response_text[:50]}...")
            return ai_response_text

        except (genai.types.BlockedPromptException, genai.types.StopCandidateException) as security_exception:
            logger.warning(f"AI ìš”ì²­/ì‘ë‹µ ì°¨ë‹¨ë¨ | ì˜¤ë¥˜: {security_exception}")
            return config.MSG_AI_BLOCKED_PROMPT
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}", exc_info=True)
            return config.MSG_AI_ERROR

    async def process_ai_message(self, message: discord.Message, weather_info: str | None = None):
        if not self.is_ready: return

        channel_config = config.CHANNEL_AI_CONFIG.get(message.channel.id)
        if not channel_config or not channel_config.get("allowed", False):
            if weather_info: await message.reply(f"ğŸ“ {weather_info}", mention_author=False)
            return

        user_query = message.content.replace(f'<@!{self.bot.user.id}>', '').replace(f'<@{self.bot.user.id}>', '').strip()
        if not user_query and not weather_info:
            await message.reply(config.MSG_AI_NO_CONTENT.format(bot_name=self.bot.user.name), mention_author=False)
            return

        async with message.channel.typing():
            ai_response_text = await self._generate_gemini_response(
                channel_id=message.channel.id,
                user_query=user_query,
                author=message.author,
                persona_config=channel_config,
                weather_info_str=weather_info
            )

            if ai_response_text:
                bot_message_obj = discord.Object(id=0)
                bot_message_obj.author = self.bot.user
                bot_message_obj.content = ai_response_text
                # ì±„ë„ ì •ë³´ë¥¼ ê°€ì§œ ê°ì²´ì— ì¶”ê°€
                bot_message_obj.channel = message.channel
                self.add_message_to_history(bot_message_obj)
                
                await message.reply(ai_response_text[:2000], mention_author=False)

    async def generate_system_alert_message(self, channel_id: int, alert_context_info: str, alert_type: str = "ì¼ë°˜ ì•Œë¦¼") -> str | None:
        if not self.is_ready:
            logger.warning(f"ì‹œìŠ¤í…œ ì•Œë¦¼({alert_type}) ìƒì„± ë¶ˆê°€: AI í•¸ë“¤ëŸ¬ ë¯¸ì¤€ë¹„.")
            return None

        channel_config = config.CHANNEL_AI_CONFIG.get(channel_id, {})
        logger.info(f"ì‹œìŠ¤í…œ {alert_type} ìƒì„± ìš”ì²­: ì±„ë„={channel_id}, ë‚´ìš©='{alert_context_info[:100]}...'")
        
        user_query_for_alert = f"ë‹¤ìŒ ìƒí™©ì„ ë„ˆì˜ í˜ë¥´ì†Œë‚˜ì— ë§ê²Œ ì±„ë„ì— ì•Œë ¤ì¤˜: '{alert_context_info}'"
        
        system_author = discord.Object(id=self.bot.user.id)
        system_author.display_name = self.bot.user.name
        
        generated_text = await self._generate_gemini_response(
            channel_id=channel_id,
            user_query=user_query_for_alert,
            author=system_author,
            persona_config=channel_config,
            is_task=True
        )
        return generated_text

async def setup(bot: commands.Bot):
    await bot.add_cog(AIHandler(bot))
